{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "from google.colab import drive\n",
        "\n",
        "# Montamos Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define la URL base y las fechas de inicio y fin\n",
        "url_base = 'https://elcomercio.pe/archivo/todas/'\n",
        "fecha_inicio = '2023-08-31'\n",
        "fecha_fin = '2023-09-30'\n",
        "\n",
        "# Lista para almacenar los DataFrames de cada fecha\n",
        "dfs = []\n",
        "\n",
        "# Carpeta de destino para guardar las imágenes\n",
        "image_folder = '/content/drive/My Drive/scrapy/Imagenes/'\n",
        "\n",
        "# Recorre las fechas desde fecha_inicio hasta fecha_fin\n",
        "current_fecha = fecha_inicio\n",
        "while current_fecha <= fecha_fin:\n",
        "    # Construye la URL con la fecha actual\n",
        "    url = f'{url_base}{current_fecha}/'\n",
        "\n",
        "    # Realizamos una solicitud GET a la página web\n",
        "    response = requests.get(url)\n",
        "\n",
        "    # Verificamos si la solicitud fue exitosa\n",
        "    if response.status_code == 200:\n",
        "        content = response.text\n",
        "\n",
        "        # Parsear el contenido HTML utilizando BeautifulSoup\n",
        "        soup = BeautifulSoup(content, 'html.parser')\n",
        "\n",
        "        # Encontrar todas las imágenes en la página\n",
        "        img_tags = soup.find_all('img', class_='story-item__img')  # Cambia 'img' por el selector adecuado para tu página web\n",
        "\n",
        "        # Lista para almacenar las rutas de las imágenes\n",
        "        image_paths = []\n",
        "\n",
        "        # Descargar las imágenes y guardar sus rutas\n",
        "        for img_tag in img_tags:\n",
        "            img_url = img_tag.get('src')\n",
        "            if img_url and img_url.startswith('http'):\n",
        "                img_response = requests.get(img_url)\n",
        "                if img_response.status_code == 200:\n",
        "                    img_filename = f'{current_fecha}_{img_url.split(\"/\")[-1]}'  # Nombre de archivo único\n",
        "                    img_path = f'{image_folder}{img_filename}'\n",
        "                    with open(img_path, 'wb') as img_file:\n",
        "                        img_file.write(img_response.content)\n",
        "                    image_paths.append(img_path)\n",
        "\n",
        "        # Crear un DataFrame de pandas con la fecha y las rutas de las imágenes\n",
        "        df = pd.DataFrame({'Fecha': [current_fecha] * len(image_paths), 'Ruta de Imagen': image_paths})\n",
        "\n",
        "        # Agregar el DataFrame a la lista\n",
        "        dfs.append(df)\n",
        "    else:\n",
        "        print(f\"No se pudo acceder a la página web para la fecha {current_fecha}.\")\n",
        "\n",
        "    # Avanzar a la siguiente fecha\n",
        "    current_fecha = pd.to_datetime(current_fecha) + pd.DateOffset(days=1)\n",
        "    current_fecha = current_fecha.strftime('%Y-%m-%d')\n",
        "\n",
        "# Concatenar todos los DataFrames en uno solo\n",
        "final_df = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "# Especifica la ruta completa del archivo CSV en tu Google Drive\n",
        "csv_filepath = '/content/drive/My Drive/scrapy/ScrapingJPG.csv'\n",
        "\n",
        "# Guardar el DataFrame en un archivo CSV en Google Drive\n",
        "final_df.to_csv(csv_filepath, index=False)\n",
        "\n",
        "print(f\"Se han descargado y guardado las imágenes junto con las fechas en '{csv_filepath}'.\")\n",
        "print(len(final_df))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RvxLNjzmQ6JN",
        "outputId": "353dda0e-3bcf-41b6-da68-1b82390f2bd5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Se han descargado y guardado las imágenes junto con las fechas en '/content/drive/My Drive/scrapy/ScrapingJPG.csv'.\n",
            "3100\n"
          ]
        }
      ]
    }
  ]
}